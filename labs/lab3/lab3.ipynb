{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSCI 573 - Feature and Model Selection\n",
    "\n",
    "# Lab 3: Ensembles and feature importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "- [Submission instructions](#si)\n",
    "- [Exercise 1: Data and preprocessing](#1)\n",
    "- [Exercise 2: Ensembles](#2)\n",
    "- [Exercise 3: Feature importances](#3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission instructions <a name=\"si\"></a>\n",
    "<hr>\n",
    "rubric={mechanics:2}\n",
    "\n",
    "You will receive marks for correctly submitting this assignment. \n",
    "\n",
    "To correctly submit this assignment follow the instructions below:\n",
    "\n",
    "- Push your assignment to your GitHub repository. \n",
    "- Add a link to your GitHub repository here: LINK TO YOUR GITHUB REPO \n",
    "- Upload an HTML render of your assignment to Canvas. The last cell of this notebook will help you do that.\n",
    "- Be sure to follow the [general lab instructions](https://ubc-mds.github.io/resources_pages/general_lab_instructions/).\n",
    "\n",
    "[Here](https://github.com/UBC-MDS/public/tree/master/rubric) you will find the description of each rubric used in MDS.\n",
    "\n",
    "**NOTE: The data you download for use in this lab SHOULD NOT BE PUSHED TO YOUR REPOSITORY. You might be penalised for pushing datasets to your repository. I have seeded the repository with `.gitignore` and hoping that it won't let you push CSVs.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "import string\n",
    "from collections import deque\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# data\n",
    "from sklearn import datasets\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "\n",
    "# Classifiers\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# classifiers / models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# other\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    RandomizedSearchCV,\n",
    "    cross_val_score,\n",
    "    cross_validate,\n",
    "    train_test_split,\n",
    ")\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Data and preprocessing <a name=\"1\"></a>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to the third lab! Because it's a quiz week, I'm trying to make this lab lighter compared to other labs. We'll be using a dataset which is smaller in size to speed things up.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall Kaggle's [Spotify Song Attributes](https://www.kaggle.com/geomack/spotifyclassification/home) dataset you used in 571 lab1. The dataset contains a number of features of songs from 2017 and a binary target variable representing whether the user liked the song or not. See the documentation of all the features [here](https://developer.spotify.com/documentation/web-api/reference/tracks/get-audio-features/). The supervised machine learning task for this dataset is predicting  whether the user likes a song or not given a number of song features.\n",
    "\n",
    "Download the CSV. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.1 \n",
    "rubric={accuracy:2,reasoning:2}\n",
    "\n",
    "**Your tasks:**\n",
    "1. Read the CSV.\n",
    "2. Split the data (80%-20%) with `random_state=123` to create `train_df` and `test_df`. \n",
    "3. Do you have class imbalance? Is one class more important than the other? What would be an appropriate metric in this problem? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution_1_1_1\n",
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution_1_1_2\n",
    "\n",
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution_1_1_3\n",
    "\n",
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**solution_1_1_3 (reasoning)**\n",
    "\n",
    "### YOUR ANSWER HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.2\n",
    "rubric={accuracy:2,reasoning:3}\n",
    "\n",
    "In 571 lab1 we excluded `artist` and `song_title` features because we did not know how to handle categorical or text features at that time. Now that we know about it, let's include `song_title` feature. \n",
    "\n",
    "**Your tasks:**\n",
    "1. How will you encode the `song_title` feature?\n",
    "2. Identify different feature types (e.g., numeric features) and store them in appropriate variables (e.g., `numeric_features`). \n",
    "\n",
    "Note: We are excluding `artist` feature in this lab. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution_1_2_1 (exploration)\n",
    "\n",
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**solution_1_2_1 (description)**\n",
    "\n",
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution_1_2_2\n",
    "\n",
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (optional) Exercise 1.3 Encoding the `artist` feature\n",
    "rubric={reasoning:1}\n",
    "\n",
    "**Your tasks:**\n",
    "1. Here we are not including the `artist` feature. How you might encode it if you decide to include it? You do not actually have to encode it but pointing out the difficulties in encoding it and providing some reasonable options will be enough. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution_1_3_1 (exploration)\n",
    "\n",
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**solution_1_3_1 (reasoning)**\n",
    "\n",
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.4 Separate `X` and `y`\n",
    "rubric={accuracy:2}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Create `X_train`, `y_train`, `X_test`, `y_test`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution_1_4_1\n",
    "\n",
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.5 Define a column transformer\n",
    "rubric={accuracy:4}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Define a column transformers called `preprocessor` using `make_column_transformer` to apply different transformations on mixed feature types:\n",
    "\n",
    "**Notes:**\n",
    "- If you are using `CountVectorizer` for encoding any of the features, use the following arguments:\n",
    "    - `stop_words=\"english\"`\n",
    "    - `max_features=200`\n",
    "- If you are not applying any transformations on certain features, do not forget to include them in the column transformer. You can do it using \"passthrough\" in a column transformer.     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution_1_5_1\n",
    "\n",
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Ensembles <a name=\"2\"></a>\n",
    "<hr>\n",
    "\n",
    "In this exercise, you may use code from lecture notes with appropriate attributions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Dummy classifier\n",
    "rubric={reasoning:1}\n",
    "\n",
    "**Your tasks:**\n",
    "1. Report mean cross-validation results along with standard deviation with the `DummyClassifier`. You can use the `strategy` of your choosing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for helper code if necessary\n",
    "\n",
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution_2_1_1\n",
    "\n",
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Decision tree\n",
    "rubric={reasoning:2}\n",
    "\n",
    "In 571 we used the decision tree classifier with the numeric features in the dataset. Let's use it as our second baseline. \n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Define a pipeline with the `preprocessor` you defined in the previous exercise and the `DecisionTreeClassifier` classifier and report mean cross-validation scores along with standard deviation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution_2_2_1\n",
    "\n",
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Different classifiers \n",
    "rubric={accuracy:5,quality:2,reasoning:4}\n",
    "\n",
    "If you haven't already done it, you'll need to install following packages in your conda environment for this exercise. If `conda install` doesn't work on your operating system for a particular package, you may have to use `pip`. \n",
    "\n",
    "```\n",
    "conda install -c conda-forge xgboost\n",
    "conda install -c conda-forge lightgbm\n",
    "conda install -c conda-forge catboost\n",
    "```\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Define pipelines for each classifier listed below using the `preprocessor` you defined in the previous exercise. Use `random_state=2` for all your classifiers. Store all the classifiers in a dictionary called `classifiers`, where keys are classifier names and values are pipelines. \n",
    "    - `LogisticRegression`\n",
    "    - `RandomForestClassifier`\n",
    "    - `XGBClassifier`\n",
    "    - `LGBMClassifier`\n",
    "    - `CatBoostClassifier`     \n",
    "2. Show mean cross-validation scores along with standard deviation for all classifiers as a dataframe. \n",
    "3. Discuss your results focusing on following points\n",
    "    - Best and worst performing models \n",
    "    - Overfitting/underfitting\n",
    "    - Fit time\n",
    "    - Score time\n",
    "    - Stability of scores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution_2_3_1\n",
    "\n",
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution_2_3_2\n",
    "\n",
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**solution_2_3_3**\n",
    "\n",
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Voting classifier \n",
    "rubric={accuracy:3,reasoning:3}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Create an averaging model using `sklearn`'s [`VotingClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html) with `soft` voting and the classifiers you used in Exercise 2.3. Show mean cross-validation scores along with standard deviation. \n",
    "2. How many models are being averaged here? Are you getting better cross-validation scores? \n",
    "3. Explain the difference between setting `voting ='soft'` vs `voting=`hard`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution_2_4_1\n",
    "\n",
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**solution_2_4_2**\n",
    "\n",
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**solution_2_4_3**\n",
    "\n",
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Stacking classifier \n",
    "rubric={accuracy:4,reasoning:1}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Create a stacking model using [`sklearn's` `StackingClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingClassifier.html) with the estimators from exercise 2.3, and logistic regression as the final estimator. You may remove `CatBoostClassifier` for speed. \n",
    "2. Show mean cross-validation scores along with standard deviation. \n",
    "3. Discuss validation scores, fit times, and score times. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution_2_5_1\n",
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution_2_5_2\n",
    "\n",
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**solution_2_5_3 (reasoning)**\n",
    "\n",
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Examine coefficients\n",
    "rubric={accuracy:3,reasoning:2}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Show feature names and their corresponding coefficients passed to the final estimator in your stacking model. \n",
    "2. Which feature has the largest (in magnitude) coefficient? What does that mean? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution_2_6_1\n",
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**solution_2_6_2**\n",
    "\n",
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (optional) 2.7 Tree-based models without scaling\n",
    "rubric={reasoning:1}\n",
    "\n",
    "Scaling should not matter for tree-based classifiers. In this exercise you'll examine whether that's true or not. \n",
    "\n",
    "**Your tasks:**\n",
    "1. Define a column transformer where you skip scaling numeric features. \n",
    "2. Show results for individual tree-based models and their averaged and stacked versions. \n",
    "3. Discuss your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution_2_7_1, solution_2_7_2\n",
    "\n",
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**solution_2_7_3 (reasoning)**\n",
    "\n",
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (optional) 2.8 Visualize a stacking classifier\n",
    "rubric={reasoning:1}\n",
    "\n",
    "**Your tasks:**\n",
    "1. Use `DecisionTreeClassifier` as the final estimator instead of logistic regression. \n",
    "2. Visualize the tree created by the model. \n",
    "3. Note your observations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution_2_8_1\n",
    "\n",
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution_2_8_2\n",
    "\n",
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**solution_2_8_3**\n",
    "\n",
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Feature importances <a name=\"3\"></a>\n",
    "<hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.1 Logistic regression coefficients\n",
    "rubric={accuracy:4}\n",
    "\n",
    "**Your tasks:**\n",
    "1. Fit the logistic regression pipeline you created in Exercise 2 on the train split. \n",
    "2. Get feature names and store them in a variable called `feature_names`. \n",
    "3. Create a dataframe with `feature_names` and corresponding coefficients. Show first 20 rows of the dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution_3_1_1\n",
    "\n",
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution_3_1_2\n",
    "\n",
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution_3_1_3\n",
    "\n",
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.2 Random forest feature importances \n",
    "rubric={accuracy:4,reasoning:2}\n",
    "\n",
    "`LogisticRegression` is quite interpretable in terms of feature importances but it didn't give us the best performance in this task. Can we get feature importances of random forest classifier, which gave us much better scores? \n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Fit the `RandomForestClassifier` pipeline you created in Exercise 2 on the train split.\n",
    "2. Examine feature importances for this random forest pipeline. You can access feature importances using `feature_importances_` attribute of the fit estimator. \n",
    "3. What features seem to be driving your predictions the most? Only from this information, can you tell in what direction they are driving the predictions? Why or why not? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution_3_2_1\n",
    "\n",
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution_3_2_2\n",
    "\n",
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**solution_3_2_3**\n",
    "### YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.3 SHAP explanations\n",
    "rubric={reasoning:5}\n",
    "\n",
    "In this exercise, we'll use [SHAP (SHapley Additive exPlanations)](https://shap.readthedocs.io/en/latest/), which is a sophisticated measure that tells us about the contribution of each feature even in non-linear models. We will use it to explain predictions made by our random forest classifier. If you haven't already done it, you'll need to install `SHAP` first. You may use the following command.  \n",
    "\n",
    "```\n",
    "conda install -c conda-forge shap\n",
    "```\n",
    "\n",
    "If it doesn't work, you might have to use `pip`.\n",
    "\n",
    "```\n",
    "pip install shap\n",
    "```\n",
    "\n",
    "In this exercise, you are given most of the code and your job is to understand the code, get it working, and comment on the plots created using shapely values. \n",
    "\n",
    "The code below\n",
    "- creates transformed `X_train` assuming that your column transformer is called `preprocessor` and the feature names of your transformed data are called `feature_names`.\n",
    "- extracts shapely values for the first 1000 examples from the training set (`X_train`) and displays them.\n",
    "- Shows a number of plots created using shapely values. \n",
    "\n",
    "**Your tasks:**\n",
    "1. Run the code. If necessary, you may adapt the starter code. \n",
    "2. Explain the dependence plot. \n",
    "3. Explain the summary plot. \n",
    "4. Explain the force plot for a specific prediction. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code creates encoded `X_train` and shows it as a dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "X_train_enc = pd.DataFrame(\n",
    "    data=preprocessor.transform(X_train).toarray(),\n",
    "    columns=feature_names,\n",
    "    index=X_train.index,\n",
    ")\n",
    "X_train_enc.head()\n",
    "\n",
    "### END STARTER CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code extracts shapely values for the first 1000 examples from the training set. (This may take a while.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train_enc, y_train)\n",
    "X_train_sample = X_train_enc.sample(1000, random_state=2)\n",
    "explainer = shap.TreeExplainer(rf)\n",
    "shap_values = explainer.shap_values(X_train_enc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code displays the shapely values for your `feature_names`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN STARTER CODE\n",
    "\n",
    "values = shap_values[0][0]\n",
    "pd.DataFrame(data=values, index=feature_names, columns=[\"SHAP\"]).sort_values(\n",
    "    by=\"SHAP\", ascending=False\n",
    ")\n",
    "\n",
    "### END STARTER CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependence plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.dependence_plot(\"danceability\", shap_values[0], X_train_enc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**solution_3_1_2** (Explain the dependence plot above.)\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "### BEGIN SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values[0], X_train_enc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**solution_3_1_3** (Explain the summary plot above.)\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "### BEGIN SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's encode the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_enc = pd.DataFrame(\n",
    "    data=preprocessor.transform(X_test).toarray(),\n",
    "    columns=feature_names,\n",
    "    index=X_test.index,\n",
    ")\n",
    "X_test_enc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's the prediction on the following test example? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.predict(X_test_enc)[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can we explain this using SHAP? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Force plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load JS visualization code to notebook\n",
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(\n",
    "    explainer.expected_value[0], shap_values[0][5, :], X_test_enc.iloc[5, :]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "**solution_3_1_4** (Explain the force plot above.)\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "\n",
    "### BEGIN SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission to Canvas\n",
    "\n",
    "**PLEASE READ: When you are ready to submit your assignment do the following:**\n",
    "\n",
    "- Run all cells in your notebook to make sure there are no errors by doing Kernel -->  Restart Kernel and Run All Cells...\n",
    "- If you are using the \"573\" `conda` environment, make sure to select it before running all cells. \n",
    "- Convert your notebook to .html format using the `convert_notebook()` function below or by File -> Export Notebook As... -> Export Notebook to HTML\n",
    "- Run the code `submit()` below to go through an interactive submission process to Canvas.\n",
    "After submission, be sure to do a final push of all your work to GitHub (including the rendered html file)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from canvasutils.submit import convert_notebook, submit\n",
    "\n",
    "# convert_notebook(\"lab3.ipynb\", \"html\")  # uncomment and run when you want to try convert your notebook (or you can convert manually from the File menu)\n",
    "# submit(course_code=59091, token=False)  # uncomment and run when ready to submit to Canvas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well done!! Congratulations on finishing the lab!! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:571]",
   "language": "python",
   "name": "conda-env-571-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
