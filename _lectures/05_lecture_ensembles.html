

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>DSCI 573: Feature and model selection &#8212; DSCI 573 Feature and Model Selection</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '_lectures/05_lecture_ensembles';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="../README.html">
  
  
  
  
    
    
      
    
    
    <img src="../_static/mds-hex-sticker.png" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="../_static/mds-hex-sticker.png" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Lectures</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../lectures/01_classification-metrics.html">Lecture 1: Classification metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../lectures/02_regression-metrics.html">Lecture 2: Regression metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../lectures/03_feature-engineering.html">Lecture 3: Feature engineering</a></li>
<li class="toctree-l1"><a class="reference internal" href="../lectures/04_feat-importances-selection.html">Lecture 4: Feature importances and feature selection</a></li>
<li class="toctree-l1"><a class="reference internal" href="../lectures/05_loss-functions-regularization_intro.html">Lecture 5: Loss functions, intro to regularization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../lectures/06_L2-L1-regularization.html">Lecture 6: L2- and L1-Regularization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../lectures/07_ensembles.html">Lecture 7: Ensembles</a></li>
<li class="toctree-l1"><a class="reference internal" href="../lectures/08_model-transparency-conclusion.html">Lecture 8: Model transparency and conclusion</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Attribution</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../attribution.html">Attributions</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/_lectures/05_lecture_ensembles.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>DSCI 573: Feature and model selection</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#lecture-5-ensembles">Lecture 5: Ensembles</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#lecture-learning-objectives">Lecture learning objectives</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#motivation">1. Motivation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-netflix-prize">The Netflix prize</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#popularity-of-treed-based-models">Popularity of treed-based models</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#data">Data</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#do-we-have-class-imbalance">Do we have class imbalance?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#baselines">Baselines</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#dummyclassifier-baseline"><code class="docutils literal notranslate"><span class="pre">DummyClassifier</span></code> baseline</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#decisiontreeclassifier-baseline"><code class="docutils literal notranslate"><span class="pre">DecisionTreeClassifier</span></code> baseline</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#random-forests">2. Random forests</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#randomforestclassifier"><code class="docutils literal notranslate"><span class="pre">RandomForestClassifier</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-a-random-forest">What is a random forest?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Random forests</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-random-forests-classifier">The random forests classifier</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#example">Example</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#some-important-hyperparameters">Some important hyperparameters:</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#random-forests-number-of-trees-n-estimators-and-the-fundamental-tradeoff">Random forests: number of trees (<code class="docutils literal notranslate"><span class="pre">n_estimators</span></code>) and the fundamental tradeoff</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#number-of-trees-and-fundamental-trade-off">Number of trees and fundamental trade-off</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#why-does-this-work">Why does this work?</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#random-forests-vs-decision-trees">Random forests vs decision trees</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#other-fancier-popular-tree-based-models">3. Other fancier popular tree-based models</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#xgboost">XGBoost</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#lightgbm">LightGBM</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#catboost">CatBoost</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#what-classifier-should-i-use">What classifier should I use?</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#averaging">4. Averaging</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#what-kind-of-estimators-can-we-combine">What kind of estimators can we combine?</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#stacking">5. Stacking</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#an-effective-strategy">An effective strategy</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#summary">Summary</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#relevant-papers">Relevant papers</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#annotated-true-or-false-questions-on-random-forests-class-discussion">(Annotated) True or False questions on Random Forests (Class discussion)</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="dsci-573-feature-and-model-selection">
<h1>DSCI 573: Feature and model selection<a class="headerlink" href="#dsci-573-feature-and-model-selection" title="Permalink to this heading">#</a></h1>
<section id="lecture-5-ensembles">
<h2>Lecture 5: Ensembles<a class="headerlink" href="#lecture-5-ensembles" title="Permalink to this heading">#</a></h2>
<p>UBC Master of Data Science program, 2020-21</p>
<p>Instructor: Varada Kolhatkar</p>
<blockquote>
The interests of truth require a diversity of opinions.    
<p>by John Stuart Mill</p>
</blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>

<span class="o">%</span><span class="k">matplotlib</span> inline
<span class="kn">import</span> <span class="nn">string</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">deque</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="c1"># data</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">datasets</span>
<span class="kn">from</span> <span class="nn">sklearn.compose</span> <span class="kn">import</span> <span class="n">ColumnTransformer</span><span class="p">,</span> <span class="n">make_column_transformer</span>
<span class="kn">from</span> <span class="nn">sklearn.dummy</span> <span class="kn">import</span> <span class="n">DummyClassifier</span><span class="p">,</span> <span class="n">DummyRegressor</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span><span class="p">,</span> <span class="n">RandomForestRegressor</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">CountVectorizer</span>

<span class="c1"># Feature selection</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="kn">import</span> <span class="n">RFE</span><span class="p">,</span> <span class="n">RFECV</span>
<span class="kn">from</span> <span class="nn">sklearn.impute</span> <span class="kn">import</span> <span class="n">SimpleImputer</span>

<span class="c1"># classifiers / models</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span><span class="p">,</span> <span class="n">LogisticRegression</span><span class="p">,</span> <span class="n">Ridge</span><span class="p">,</span> <span class="n">RidgeCV</span>

<span class="c1"># other</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">log_loss</span><span class="p">,</span> <span class="n">make_scorer</span><span class="p">,</span> <span class="n">mean_squared_error</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">GridSearchCV</span><span class="p">,</span>
    <span class="n">RandomizedSearchCV</span><span class="p">,</span>
    <span class="n">ShuffleSplit</span><span class="p">,</span>
    <span class="n">cross_val_score</span><span class="p">,</span>
    <span class="n">cross_validate</span><span class="p">,</span>
    <span class="n">train_test_split</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span><span class="p">,</span> <span class="n">make_pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">OneHotEncoder</span><span class="p">,</span>
    <span class="n">OrdinalEncoder</span><span class="p">,</span>
    <span class="n">PolynomialFeatures</span><span class="p">,</span>
    <span class="n">StandardScaler</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span><span class="p">,</span> <span class="n">SVR</span>
<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># copied from 571 lecture 1</span>
<span class="kn">import</span> <span class="nn">re</span>

<span class="kn">import</span> <span class="nn">graphviz</span>
<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">export_graphviz</span>


<span class="k">def</span> <span class="nf">display_tree</span><span class="p">(</span><span class="n">feature_names</span><span class="p">,</span> <span class="n">tree</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot; For binary classification only &quot;&quot;&quot;</span>
    <span class="n">dot</span> <span class="o">=</span> <span class="n">export_graphviz</span><span class="p">(</span>
        <span class="n">tree</span><span class="p">,</span>
        <span class="n">out_file</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">feature_names</span><span class="o">=</span><span class="n">feature_names</span><span class="p">,</span>
        <span class="n">class_names</span><span class="o">=</span><span class="n">tree</span><span class="o">.</span><span class="n">classes_</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">str</span><span class="p">),</span>
        <span class="n">impurity</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">precision</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="c1"># adapted from https://stackoverflow.com/questions/44821349/python-graphviz-remove-legend-on-nodes-of-decisiontreeclassifier</span>
    <span class="n">dot</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span>
        <span class="s2">&quot;(</span><span class="se">\\\\</span><span class="s2">nsamples = [0-9]+)(</span><span class="se">\\\\</span><span class="s2">nvalue = \[[0-9]+, [0-9]+\])(</span><span class="se">\\\\</span><span class="s2">nclass = [A-Za-z0-9]+)&quot;</span><span class="p">,</span>
        <span class="s2">&quot;&quot;</span><span class="p">,</span>
        <span class="n">dot</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">dot</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s2">&quot;(samples = [0-9]+)(</span><span class="se">\\\\</span><span class="s2">nvalue = \[[0-9]+, [0-9]+\])</span><span class="se">\\\\</span><span class="s2">n&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">dot</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">graphviz</span><span class="o">.</span><span class="n">Source</span><span class="p">(</span><span class="n">dot</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="lecture-learning-objectives">
<h2>Lecture learning objectives<a class="headerlink" href="#lecture-learning-objectives" title="Permalink to this heading">#</a></h2>
<p>From this lecture, you will be able to</p>
<ul class="simple">
<li><p>Use <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code>’s <code class="docutils literal notranslate"><span class="pre">RandomForestClassifier</span></code> and explain its main hyperparameters.</p></li>
<li><p>Explain randomness in random forest algorithm.</p></li>
<li><p>Use other tree-based models such as as <code class="docutils literal notranslate"><span class="pre">XGBoost</span></code> and <code class="docutils literal notranslate"><span class="pre">LGBM</span></code>.</p></li>
<li><p>Employ ensemble classifier approaches, in particular model averaging and stacking.</p></li>
<li><p>Explain voting and stacking and the differences between them.</p></li>
<li><p>Use <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code> implementations of these ensemble methods.</p></li>
</ul>
</section>
<section id="motivation">
<h2>1. Motivation<a class="headerlink" href="#motivation" title="Permalink to this heading">#</a></h2>
<section id="the-netflix-prize">
<h3>The Netflix prize<a class="headerlink" href="#the-netflix-prize" title="Permalink to this heading">#</a></h3>
<p><img alt="image.png" src="_lectures/attachment:image.png" /></p>
<p><a class="reference external" href="https://netflixtechblog.com/netflix-recommendations-beyond-the-5-stars-part-1-55838468f429">Source</a></p>
<ul class="simple">
<li><p>Most of the winning solutions for Kaggle competitions involve some kind of ensembling. For example:</p></li>
</ul>
<a class="reference internal image-reference" href="../_images/fraud_detection_kaggle.png"><img alt="../_images/fraud_detection_kaggle.png" src="../_images/fraud_detection_kaggle.png" style="width: 800px; height: 800px;" /></a>
<p>So far we have the following models in our toolbox:</p>
<ul class="simple">
<li><p>Decision trees</p></li>
<li><p><span class="math notranslate nohighlight">\(k\)</span>-nearest neighbours</p></li>
<li><p>SVM RBF</p></li>
<li><p>Naive Bayes</p></li>
<li><p>Logistic regression</p></li>
</ul>
<ul class="simple">
<li><p>Idea: Groups can often make better decisions than individuals, especially when group members are diverse enough.</p></li>
</ul>
<p><a class="reference external" href="http://wisdomofcrowds.blogspot.com/2009/12/introduction-part-i.html">The Wisdom of Crowds</a></p>
<a class="reference internal image-reference" href="../_images/wisdom_of_crowds.jpg"><img alt="../_images/wisdom_of_crowds.jpg" src="../_images/wisdom_of_crowds.jpg" style="width: 400px; height: 400px;" /></a>
</section>
<section id="popularity-of-treed-based-models">
<h3>Popularity of treed-based models<a class="headerlink" href="#popularity-of-treed-based-models" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>Decision trees models are</p>
<ul>
<li><p>Interpretable</p></li>
<li><p>The can capture non-linear relationships</p></li>
<li><p>They don’t require scaling of the data and theoretically can work with categorical features.</p></li>
</ul>
</li>
<li><p>But with a single decision trees are likely to overfit.</p></li>
<li><p>Idea: Combine multiple trees to build stronger models.</p>
<ul>
<li><p>These kinds of models are extremely popular in industry.</p></li>
</ul>
</li>
</ul>
</section>
<section id="data">
<h3>Data<a class="headerlink" href="#data" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>Let’s work with <a class="reference external" href="https://www.kaggle.com/uciml/adult-census-income">the adult census data set</a> we used in 571.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">adult_df_large</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;data/adult.csv&quot;</span><span class="p">)</span>
<span class="n">train_df</span><span class="p">,</span> <span class="n">test_df</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">adult_df_large</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">train_df_nan</span> <span class="o">=</span> <span class="n">train_df</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;?&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">NaN</span><span class="p">)</span>
<span class="n">test_df_nan</span> <span class="o">=</span> <span class="n">test_df</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;?&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">NaN</span><span class="p">)</span>
<span class="n">train_df_nan</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>age</th>
      <th>workclass</th>
      <th>fnlwgt</th>
      <th>education</th>
      <th>education.num</th>
      <th>marital.status</th>
      <th>occupation</th>
      <th>relationship</th>
      <th>race</th>
      <th>sex</th>
      <th>capital.gain</th>
      <th>capital.loss</th>
      <th>hours.per.week</th>
      <th>native.country</th>
      <th>income</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>5514</th>
      <td>26</td>
      <td>Private</td>
      <td>256263</td>
      <td>HS-grad</td>
      <td>9</td>
      <td>Never-married</td>
      <td>Craft-repair</td>
      <td>Not-in-family</td>
      <td>White</td>
      <td>Male</td>
      <td>0</td>
      <td>0</td>
      <td>25</td>
      <td>United-States</td>
      <td>&lt;=50K</td>
    </tr>
    <tr>
      <th>19777</th>
      <td>24</td>
      <td>Private</td>
      <td>170277</td>
      <td>HS-grad</td>
      <td>9</td>
      <td>Never-married</td>
      <td>Other-service</td>
      <td>Not-in-family</td>
      <td>White</td>
      <td>Female</td>
      <td>0</td>
      <td>0</td>
      <td>35</td>
      <td>United-States</td>
      <td>&lt;=50K</td>
    </tr>
    <tr>
      <th>10781</th>
      <td>36</td>
      <td>Private</td>
      <td>75826</td>
      <td>Bachelors</td>
      <td>13</td>
      <td>Divorced</td>
      <td>Adm-clerical</td>
      <td>Unmarried</td>
      <td>White</td>
      <td>Female</td>
      <td>0</td>
      <td>0</td>
      <td>40</td>
      <td>United-States</td>
      <td>&lt;=50K</td>
    </tr>
    <tr>
      <th>32240</th>
      <td>22</td>
      <td>State-gov</td>
      <td>24395</td>
      <td>Some-college</td>
      <td>10</td>
      <td>Married-civ-spouse</td>
      <td>Adm-clerical</td>
      <td>Wife</td>
      <td>White</td>
      <td>Female</td>
      <td>0</td>
      <td>0</td>
      <td>20</td>
      <td>United-States</td>
      <td>&lt;=50K</td>
    </tr>
    <tr>
      <th>9876</th>
      <td>31</td>
      <td>Local-gov</td>
      <td>356689</td>
      <td>Bachelors</td>
      <td>13</td>
      <td>Married-civ-spouse</td>
      <td>Prof-specialty</td>
      <td>Husband</td>
      <td>White</td>
      <td>Male</td>
      <td>0</td>
      <td>0</td>
      <td>40</td>
      <td>United-States</td>
      <td>&lt;=50K</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">numeric_features</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;age&quot;</span><span class="p">,</span> <span class="s2">&quot;fnlwgt&quot;</span><span class="p">,</span> <span class="s2">&quot;capital.gain&quot;</span><span class="p">,</span> <span class="s2">&quot;capital.loss&quot;</span><span class="p">,</span> <span class="s2">&quot;hours.per.week&quot;</span><span class="p">]</span>
<span class="n">categorical_features</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;workclass&quot;</span><span class="p">,</span>
    <span class="s2">&quot;marital.status&quot;</span><span class="p">,</span>
    <span class="s2">&quot;occupation&quot;</span><span class="p">,</span>
    <span class="s2">&quot;relationship&quot;</span><span class="p">,</span>
    <span class="s2">&quot;native.country&quot;</span><span class="p">,</span>
<span class="p">]</span>
<span class="n">ordinal_features</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;education&quot;</span><span class="p">]</span>
<span class="n">binary_features</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;sex&quot;</span><span class="p">]</span>
<span class="n">drop_features</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;race&quot;</span><span class="p">,</span> <span class="s2">&quot;education.num&quot;</span><span class="p">]</span>
<span class="n">target_column</span> <span class="o">=</span> <span class="s2">&quot;income&quot;</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">education_levels</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;Preschool&quot;</span><span class="p">,</span>
    <span class="s2">&quot;1st-4th&quot;</span><span class="p">,</span>
    <span class="s2">&quot;5th-6th&quot;</span><span class="p">,</span>
    <span class="s2">&quot;7th-8th&quot;</span><span class="p">,</span>
    <span class="s2">&quot;9th&quot;</span><span class="p">,</span>
    <span class="s2">&quot;10th&quot;</span><span class="p">,</span>
    <span class="s2">&quot;11th&quot;</span><span class="p">,</span>
    <span class="s2">&quot;12th&quot;</span><span class="p">,</span>
    <span class="s2">&quot;HS-grad&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Prof-school&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Assoc-voc&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Assoc-acdm&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Some-college&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Bachelors&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Masters&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Doctorate&quot;</span><span class="p">,</span>
<span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">assert</span> <span class="nb">set</span><span class="p">(</span><span class="n">education_levels</span><span class="p">)</span> <span class="o">==</span> <span class="nb">set</span><span class="p">(</span><span class="n">train_df</span><span class="p">[</span><span class="s2">&quot;education&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">numeric_transformer</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">SimpleImputer</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s2">&quot;median&quot;</span><span class="p">),</span> <span class="n">StandardScaler</span><span class="p">())</span>
<span class="n">tree_numeric_transformer</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">SimpleImputer</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s2">&quot;median&quot;</span><span class="p">))</span>

<span class="n">categorical_transformer</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span>
    <span class="n">SimpleImputer</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s2">&quot;constant&quot;</span><span class="p">,</span> <span class="n">fill_value</span><span class="o">=</span><span class="s2">&quot;missing&quot;</span><span class="p">),</span>
    <span class="n">OneHotEncoder</span><span class="p">(</span><span class="n">handle_unknown</span><span class="o">=</span><span class="s2">&quot;ignore&quot;</span><span class="p">),</span>
<span class="p">)</span>

<span class="n">ordinal_transformer</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span>
    <span class="n">SimpleImputer</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s2">&quot;constant&quot;</span><span class="p">,</span> <span class="n">fill_value</span><span class="o">=</span><span class="s2">&quot;missing&quot;</span><span class="p">),</span>
    <span class="n">OrdinalEncoder</span><span class="p">(</span><span class="n">categories</span><span class="o">=</span><span class="p">[</span><span class="n">education_levels</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">),</span>
<span class="p">)</span>

<span class="n">binary_transformer</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span>
    <span class="n">SimpleImputer</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s2">&quot;constant&quot;</span><span class="p">,</span> <span class="n">fill_value</span><span class="o">=</span><span class="s2">&quot;missing&quot;</span><span class="p">),</span>
    <span class="n">OneHotEncoder</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="s2">&quot;if_binary&quot;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">),</span>
<span class="p">)</span>

<span class="n">preprocessor</span> <span class="o">=</span> <span class="n">make_column_transformer</span><span class="p">(</span>
    <span class="p">(</span><span class="s2">&quot;drop&quot;</span><span class="p">,</span> <span class="n">drop_features</span><span class="p">),</span>
    <span class="p">(</span><span class="n">numeric_transformer</span><span class="p">,</span> <span class="n">numeric_features</span><span class="p">),</span>
    <span class="p">(</span><span class="n">ordinal_transformer</span><span class="p">,</span> <span class="n">ordinal_features</span><span class="p">),</span>
    <span class="p">(</span><span class="n">binary_transformer</span><span class="p">,</span> <span class="n">binary_features</span><span class="p">),</span>
    <span class="p">(</span><span class="n">categorical_transformer</span><span class="p">,</span> <span class="n">categorical_features</span><span class="p">),</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span> <span class="o">=</span> <span class="n">train_df_nan</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="n">target_column</span><span class="p">])</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">train_df_nan</span><span class="p">[</span><span class="n">target_column</span><span class="p">]</span>

<span class="n">X_test</span> <span class="o">=</span> <span class="n">test_df_nan</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="n">target_column</span><span class="p">])</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">test_df_nan</span><span class="p">[</span><span class="n">target_column</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="do-we-have-class-imbalance">
<h3>Do we have class imbalance?<a class="headerlink" href="#do-we-have-class-imbalance" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>There is class imbalance. But without any context, both classes seem equally important.</p></li>
<li><p>Let’s use accuracy as our metric.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_df_nan</span><span class="p">[</span><span class="s2">&quot;income&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;=50K    0.757985
&gt;50K     0.242015
Name: income, dtype: float64
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">scoring_metric</span> <span class="o">=</span> <span class="s2">&quot;accuracy&quot;</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s store all the results in a dictionary called <code class="docutils literal notranslate"><span class="pre">results</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">results</span> <span class="o">=</span> <span class="p">{}</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">mean_std_cross_val_scores</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns mean and std of cross validation</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">scores</span> <span class="o">=</span> <span class="n">cross_validate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="n">mean_scores</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="n">std_scores</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span><span class="o">.</span><span class="n">std</span><span class="p">()</span>
    <span class="n">out_col</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">mean_scores</span><span class="p">)):</span>
        <span class="n">out_col</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="sa">f</span><span class="s2">&quot;%0.3f (+/- %0.3f)&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">mean_scores</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">std_scores</span><span class="p">[</span><span class="n">i</span><span class="p">])))</span>

    <span class="k">return</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">out_col</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">mean_scores</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="baselines">
<h3>Baselines<a class="headerlink" href="#baselines" title="Permalink to this heading">#</a></h3>
</section>
<section id="dummyclassifier-baseline">
<h3><code class="docutils literal notranslate"><span class="pre">DummyClassifier</span></code> baseline<a class="headerlink" href="#dummyclassifier-baseline" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dummy</span> <span class="o">=</span> <span class="n">DummyClassifier</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s2">&quot;stratified&quot;</span><span class="p">)</span>
<span class="n">results</span><span class="p">[</span><span class="s2">&quot;Dummy&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">mean_std_cross_val_scores</span><span class="p">(</span>
    <span class="n">dummy</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="n">scoring_metric</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="decisiontreeclassifier-baseline">
<h3><code class="docutils literal notranslate"><span class="pre">DecisionTreeClassifier</span></code> baseline<a class="headerlink" href="#decisiontreeclassifier-baseline" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>Let’s try decision tree classifier on our data.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pipe_dt</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">preprocessor</span><span class="p">,</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">123</span><span class="p">))</span>
<span class="n">results</span><span class="p">[</span><span class="s2">&quot;Decision tree&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">mean_std_cross_val_scores</span><span class="p">(</span>
    <span class="n">pipe_dt</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="n">scoring_metric</span>
<span class="p">)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Dummy</th>
      <th>Decision tree</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>fit_time</th>
      <td>0.007 (+/- 0.001)</td>
      <td>0.461 (+/- 0.015)</td>
    </tr>
    <tr>
      <th>score_time</th>
      <td>0.005 (+/- 0.000)</td>
      <td>0.020 (+/- 0.000)</td>
    </tr>
    <tr>
      <th>test_score</th>
      <td>0.633 (+/- 0.008)</td>
      <td>0.813 (+/- 0.003)</td>
    </tr>
    <tr>
      <th>train_score</th>
      <td>0.636 (+/- 0.004)</td>
      <td>1.000 (+/- 0.000)</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Decision tree is terribly overfitting.</p>
</section>
</section>
<section id="random-forests">
<h2>2. Random forests<a class="headerlink" href="#random-forests" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>Video 2</p></li>
</ul>
<section id="randomforestclassifier">
<h3><code class="docutils literal notranslate"><span class="pre">RandomForestClassifier</span></code><a class="headerlink" href="#randomforestclassifier" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pipe_rf</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">preprocessor</span><span class="p">,</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">123</span><span class="p">))</span>
<span class="n">results</span><span class="p">[</span><span class="s2">&quot;Random forests&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">mean_std_cross_val_scores</span><span class="p">(</span>
    <span class="n">pipe_rf</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="n">scoring_metric</span>
<span class="p">)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Dummy</th>
      <th>Decision tree</th>
      <th>Random forests</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>fit_time</th>
      <td>0.007 (+/- 0.001)</td>
      <td>0.463 (+/- 0.011)</td>
      <td>6.891 (+/- 0.075)</td>
    </tr>
    <tr>
      <th>score_time</th>
      <td>0.005 (+/- 0.000)</td>
      <td>0.020 (+/- 0.000)</td>
      <td>0.096 (+/- 0.002)</td>
    </tr>
    <tr>
      <th>test_score</th>
      <td>0.634 (+/- 0.008)</td>
      <td>0.813 (+/- 0.003)</td>
      <td>0.857 (+/- 0.004)</td>
    </tr>
    <tr>
      <th>train_score</th>
      <td>0.631 (+/- 0.002)</td>
      <td>1.000 (+/- 0.000)</td>
      <td>1.000 (+/- 0.000)</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>The validation scores are better although it seems likes we are still overfitting.</p>
</section>
<section id="what-is-a-random-forest">
<h3>What is a random forest?<a class="headerlink" href="#what-is-a-random-forest" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>A popular, off-the-shelf tree-based model.</p></li>
<li><p>General idea</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">fit</span></code> a diverse set of decision trees by <strong>injecting randomness</strong> in the classifier construction</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">predict</span></code> by taking the average of predictions given by individual classifiers</p></li>
</ul>
</li>
</ul>
</section>
<section id="id1">
<h3>Random forests<a class="headerlink" href="#id1" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>How do we inject randomness in the classifier construction?</p>
<ol class="arabic simple">
<li><p>Data: <strong>Build each tree on a bootstrap sample</strong> (i.e., a sample drawn <strong>with replacement</strong> from the training set)</p></li>
<li><p>Features: Consider a <strong>random subset of features at each split</strong>.</p></li>
</ol>
</li>
</ul>
<p>Note: There is also something called <code class="docutils literal notranslate"><span class="pre">ExtraTreesClassifier</span></code>, where we add more randomness by consider a random subset of features at each split and <strong>random threshold</strong>.</p>
</section>
<section id="the-random-forests-classifier">
<h3>The random forests classifier<a class="headerlink" href="#the-random-forests-classifier" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>Create a collection (ensemble) of trees. Grow each tree on an independent bootstrap sample from the data.</p></li>
<li><p>At each node:</p>
<ul>
<li><p>Randomly select a subset of features out of all features (independently for each node).</p></li>
<li><p>Find the best split on the selected features.</p></li>
<li><p>Grow the trees to maximum depth.</p></li>
</ul>
</li>
<li><p>Prediction time</p>
<ul>
<li><p>Vote the trees to get predictions for new example.</p></li>
</ul>
</li>
</ul>
</section>
<section id="example">
<h3>Example<a class="headerlink" href="#example" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>Let’s create a random forest with 3 estimators.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pipe_rf_demo</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span>
    <span class="n">preprocessor</span><span class="p">,</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">123</span><span class="p">)</span>
<span class="p">)</span>
<span class="n">pipe_rf_demo</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Let’s get the feature names of transformed features.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">feature_names</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">numeric_features</span>
    <span class="o">+</span> <span class="n">ordinal_features</span>
    <span class="o">+</span> <span class="n">binary_features</span>
    <span class="o">+</span> <span class="nb">list</span><span class="p">(</span>
        <span class="n">pipe_rf_demo</span><span class="o">.</span><span class="n">named_steps</span><span class="p">[</span><span class="s2">&quot;columntransformer&quot;</span><span class="p">]</span>
        <span class="o">.</span><span class="n">named_transformers_</span><span class="p">[</span><span class="s2">&quot;pipeline-4&quot;</span><span class="p">]</span>
        <span class="o">.</span><span class="n">named_steps</span><span class="p">[</span><span class="s2">&quot;onehotencoder&quot;</span><span class="p">]</span>
        <span class="o">.</span><span class="n">get_feature_names</span><span class="p">()</span>
    <span class="p">)</span>
<span class="p">)</span>
<span class="n">feature_names</span><span class="p">[:</span><span class="mi">10</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;age&#39;,
 &#39;fnlwgt&#39;,
 &#39;capital.gain&#39;,
 &#39;capital.loss&#39;,
 &#39;hours.per.week&#39;,
 &#39;education&#39;,
 &#39;sex&#39;,
 &#39;x0_Federal-gov&#39;,
 &#39;x0_Local-gov&#39;,
 &#39;x0_Never-worked&#39;]
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Let’s sample a test example.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">test_example</span> <span class="o">=</span> <span class="n">X_test</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Classes: &quot;</span><span class="p">,</span> <span class="n">pipe_rf_demo</span><span class="o">.</span><span class="n">classes_</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Prediction by random forest: &quot;</span><span class="p">,</span> <span class="n">pipe_rf_demo</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_example</span><span class="p">))</span>
<span class="n">transformed_example</span> <span class="o">=</span> <span class="n">preprocessor</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">test_example</span><span class="p">)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">transformed_example</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">index</span><span class="o">=</span><span class="n">feature_names</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Classes:  [&#39;&lt;=50K&#39; &#39;&gt;50K&#39;]
Prediction by random forest:  [&#39;&gt;50K&#39;]
</pre></div>
</div>
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>age</th>
      <td>0.991591</td>
    </tr>
    <tr>
      <th>fnlwgt</th>
      <td>-0.357945</td>
    </tr>
    <tr>
      <th>capital.gain</th>
      <td>13.153284</td>
    </tr>
    <tr>
      <th>capital.loss</th>
      <td>-0.217680</td>
    </tr>
    <tr>
      <th>hours.per.week</th>
      <td>-0.042081</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
    </tr>
    <tr>
      <th>x4_Trinadad&amp;Tobago</th>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>x4_United-States</th>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>x4_Vietnam</th>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>x4_Yugoslavia</th>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>x4_missing</th>
      <td>0.000000</td>
    </tr>
  </tbody>
</table>
<p>86 rows × 1 columns</p>
</div></div></div>
</div>
<ul class="simple">
<li><p>We can look at different trees created by random forest.</p></li>
<li><p>Note that each tree looks at different set of features and slightly different data.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">tree</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span>
    <span class="n">pipe_rf_demo</span><span class="o">.</span><span class="n">named_steps</span><span class="p">[</span><span class="s2">&quot;randomforestclassifier&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">estimators_</span>
<span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n\n</span><span class="s2">Tree&quot;</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">display</span><span class="p">(</span><span class="n">display_tree</span><span class="p">(</span><span class="n">feature_names</span><span class="p">,</span> <span class="n">tree</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;prediction&quot;</span><span class="p">,</span> <span class="n">tree</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">preprocessor</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">test_example</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Tree 1
</pre></div>
</div>
<img alt="../_images/c2f1bfc5909616dcaadac1ce2939236565b1ee48e2f02516c2ecc6c727ec38b6.svg" src="../_images/c2f1bfc5909616dcaadac1ce2939236565b1ee48e2f02516c2ecc6c727ec38b6.svg" /><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>prediction [1.]


Tree 2
</pre></div>
</div>
<img alt="../_images/dc6abacf0ca955192e70c54ccece3e5f4c8e784dd3f8bf4e58a0c7a5c039cc9d.svg" src="../_images/dc6abacf0ca955192e70c54ccece3e5f4c8e784dd3f8bf4e58a0c7a5c039cc9d.svg" /><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>prediction [0.]


Tree 3
</pre></div>
</div>
<img alt="../_images/93ea0bdb63787d43e66916b8c1e5cd95922097100a4fa4236d41ab85b095534e.svg" src="../_images/93ea0bdb63787d43e66916b8c1e5cd95922097100a4fa4236d41ab85b095534e.svg" /><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>prediction [1.]
</pre></div>
</div>
</div>
</div>
</section>
<section id="some-important-hyperparameters">
<h3>Some important hyperparameters:<a class="headerlink" href="#some-important-hyperparameters" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">n_estimators</span></code>: number of decision trees (higher = more complexity)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">max_depth</span></code>: max depth of each decision tree (higher = more complexity)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">max_features</span></code>: the number of features you get to look at each split (higher = more complexity)</p></li>
</ul>
</section>
<section id="random-forests-number-of-trees-n-estimators-and-the-fundamental-tradeoff">
<h3>Random forests: number of trees (<code class="docutils literal notranslate"><span class="pre">n_estimators</span></code>) and the fundamental tradeoff<a class="headerlink" href="#random-forests-number-of-trees-n-estimators-and-the-fundamental-tradeoff" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">make_num_tree_plot</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">num_trees</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Make number of trees vs error rate plot for RandomForestClassifier</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    model: sklearn classifier model</span>
<span class="sd">        The sklearn model</span>
<span class="sd">    X_train: numpy.ndarray</span>
<span class="sd">        The X part of the train set</span>
<span class="sd">    y_train: numpy.ndarray</span>
<span class="sd">        The y part of the train set</span>
<span class="sd">    X_test: numpy.ndarray</span>
<span class="sd">        The X part of the test/validation set</span>
<span class="sd">    y_test: numpy.ndarray</span>
<span class="sd">        The y part of the test/validation set</span>
<span class="sd">    num_trees: int</span>
<span class="sd">        The value for `n_estimators` argument of RandomForestClassifier</span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">        None</span>
<span class="sd">        Shows the number of trees vs error rate plot</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">train_scores</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">test_scores</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">ntree</span> <span class="ow">in</span> <span class="n">num_trees</span><span class="p">:</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">preprocessor</span><span class="p">,</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="n">ntree</span><span class="p">))</span>
        <span class="n">scores</span> <span class="o">=</span> <span class="n">cross_validate</span><span class="p">(</span>
            <span class="n">model</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="n">scoring_metric</span>
        <span class="p">)</span>
        <span class="n">train_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">scores</span><span class="p">[</span><span class="s2">&quot;train_score&quot;</span><span class="p">]))</span>
        <span class="n">test_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">scores</span><span class="p">[</span><span class="s2">&quot;test_score&quot;</span><span class="p">]))</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">semilogx</span><span class="p">(</span><span class="n">num_trees</span><span class="p">,</span> <span class="n">train_scores</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;train&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">semilogx</span><span class="p">(</span><span class="n">num_trees</span><span class="p">,</span> <span class="n">test_scores</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;cv&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;number of trees&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;scores&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">make_num_tree_plot</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">500</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/87acc097244b565d7705596163089e521dc3154d3e02f0be8ba865fdc238ce29.png" src="../_images/87acc097244b565d7705596163089e521dc3154d3e02f0be8ba865fdc238ce29.png" />
</div>
</div>
<section id="number-of-trees-and-fundamental-trade-off">
<h4>Number of trees and fundamental trade-off<a class="headerlink" href="#number-of-trees-and-fundamental-trade-off" title="Permalink to this heading">#</a></h4>
<ul class="simple">
<li><p>Above: seems like we’re beating the fundamental “tradeoff” by increasing training score and not decreasing validation score much.</p></li>
<li><p>This is the promise of ensembles, though it’s not guaranteed to work so nicely.</p></li>
</ul>
<p>More trees are always better! We pick less trees for speed.</p>
</section>
<section id="why-does-this-work">
<h4>Why does this work?<a class="headerlink" href="#why-does-this-work" title="Permalink to this heading">#</a></h4>
<ul class="simple">
<li><p>The idea is that if you have many weak learners that only need to perform marginally better than random guessing.</p></li>
</ul>
</section>
</section>
<section id="random-forests-vs-decision-trees">
<h3>Random forests vs decision trees<a class="headerlink" href="#random-forests-vs-decision-trees" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>Accuracy</p>
<ul>
<li><p>Random forests are usually more accurate compared to decision trees, in fact they are usually one of the best performing off-the-shelf classifiers.</p></li>
<li><p><a class="reference external" href="https://www.stat.berkeley.edu/~breiman/randomforest2001.pdf">The original random forests paper</a> by Leo Breiman notes that the error rate depends upon the following:</p>
<ul>
<li><p>The correlation between any two trees in the forest. Higher the correlation higher the error rate.</p></li>
<li><p>The error rate of each individual tree in the forest. Lowering the error rate of the individual trees decreases the forest error rate.</p></li>
</ul>
</li>
</ul>
</li>
<li><p>Speed?</p>
<ul>
<li><p>Slower than decision trees because we are fitting multiple trees</p></li>
<li><p>But can easily parallelize training because all trees are independent of each other</p></li>
</ul>
</li>
<li><p>Overfitting</p>
<ul>
<li><p>No depth decision tree tends to overfit</p></li>
<li><p>Random forests are less likely to overfit</p></li>
</ul>
</li>
<li><p>Interpretability</p>
<ul>
<li><p>Decision trees are more interpretable</p></li>
</ul>
</li>
</ul>
</section>
<section id="other-fancier-popular-tree-based-models">
<h3>3. Other fancier popular tree-based models<a class="headerlink" href="#other-fancier-popular-tree-based-models" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>Video 3</p></li>
</ul>
<p>Three popular and effective tree-based models</p>
<ul class="simple">
<li><p><a class="reference external" href="https://xgboost.readthedocs.io/en/latest/">XGBoost</a></p></li>
<li><p><a class="reference external" href="https://lightgbm.readthedocs.io/en/latest/Python-Intro.html">LightGBM</a></p></li>
<li><p><a class="reference external" href="https://catboost.ai/docs/concepts/python-quickstart.html">CatBoost</a></p></li>
</ul>
<p>We’ll not go into details.</p>
</section>
<section id="xgboost">
<h3>XGBoost<a class="headerlink" href="#xgboost" title="Permalink to this heading">#</a></h3>
<ul>
<li><p>Not part of <code class="docutils literal notranslate"><span class="pre">sklearn</span></code> but has similar interface.</p></li>
<li><p>Install it in your conda environment.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">conda</span> <span class="n">install</span> <span class="o">-</span><span class="n">c</span> <span class="n">conda</span><span class="o">-</span><span class="n">forge</span> <span class="n">xgboost</span>
</pre></div>
</div>
</li>
<li><p>Supports missing values</p></li>
<li><p>GPU training</p></li>
<li><p>Networked parallel training</p></li>
<li><p>Supports sparse data</p></li>
<li><p>Typically better scores than random forests</p></li>
</ul>
</section>
<section id="lightgbm">
<h3>LightGBM<a class="headerlink" href="#lightgbm" title="Permalink to this heading">#</a></h3>
<ul>
<li><p>Not part of <code class="docutils literal notranslate"><span class="pre">sklearn</span></code> but has similar interface.</p></li>
<li><p>Install it in your conda environment.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">conda</span> <span class="n">install</span> <span class="o">-</span><span class="n">c</span> <span class="n">conda</span><span class="o">-</span><span class="n">forge</span> <span class="n">lightgbm</span>
</pre></div>
</div>
</li>
<li><p>Small model size</p></li>
<li><p>Faster</p></li>
<li><p>Typically better scores than random forests</p></li>
</ul>
</section>
<section id="catboost">
<h3>CatBoost<a class="headerlink" href="#catboost" title="Permalink to this heading">#</a></h3>
<ul>
<li><p>Not part of <code class="docutils literal notranslate"><span class="pre">sklearn</span></code> but has similar interface.</p></li>
<li><p>Install it in your conda environment.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">conda</span> <span class="n">install</span> <span class="o">-</span><span class="n">c</span> <span class="n">conda</span><span class="o">-</span><span class="n">forge</span> <span class="n">catboost</span>
</pre></div>
</div>
</li>
<li><p>Usually better scores but slower compared to <code class="docutils literal notranslate"><span class="pre">XGBoost</span></code> and <code class="docutils literal notranslate"><span class="pre">LightGBM</span></code></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">catboost</span> <span class="kn">import</span> <span class="n">CatBoostClassifier</span>
<span class="kn">from</span> <span class="nn">lightgbm.sklearn</span> <span class="kn">import</span> <span class="n">LGBMClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>
<span class="kn">from</span> <span class="nn">xgboost</span> <span class="kn">import</span> <span class="n">XGBClassifier</span>

<span class="n">pipe_lr</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span>
    <span class="n">preprocessor</span><span class="p">,</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">2000</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">123</span><span class="p">)</span>
<span class="p">)</span>
<span class="n">pipe_dt</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">preprocessor</span><span class="p">,</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">123</span><span class="p">))</span>
<span class="n">pipe_rf</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">preprocessor</span><span class="p">,</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">123</span><span class="p">))</span>
<span class="n">pipe_xgb</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">preprocessor</span><span class="p">,</span> <span class="n">XGBClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">123</span><span class="p">))</span>
<span class="n">pipe_lgbm</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">preprocessor</span><span class="p">,</span> <span class="n">LGBMClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">123</span><span class="p">))</span>
<span class="n">pipe_catboost</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span>
    <span class="n">preprocessor</span><span class="p">,</span> <span class="n">CatBoostClassifier</span><span class="p">(</span><span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">123</span><span class="p">)</span>
<span class="p">)</span>
<span class="n">classifiers</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;logistic regression&quot;</span><span class="p">:</span> <span class="n">pipe_lr</span><span class="p">,</span>
    <span class="s2">&quot;decision tree&quot;</span><span class="p">:</span> <span class="n">pipe_dt</span><span class="p">,</span>
    <span class="s2">&quot;random forest&quot;</span><span class="p">:</span> <span class="n">pipe_rf</span><span class="p">,</span>
    <span class="s2">&quot;XGBoost&quot;</span><span class="p">:</span> <span class="n">pipe_xgb</span><span class="p">,</span>
    <span class="s2">&quot;LightGBM&quot;</span><span class="p">:</span> <span class="n">pipe_lgbm</span><span class="p">,</span>
    <span class="s2">&quot;CatBoost&quot;</span><span class="p">:</span> <span class="n">pipe_catboost</span><span class="p">,</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dummy</span> <span class="o">=</span> <span class="n">DummyClassifier</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s2">&quot;stratified&quot;</span><span class="p">)</span>
<span class="n">results</span><span class="p">[</span><span class="s2">&quot;Dummy&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">mean_std_cross_val_scores</span><span class="p">(</span>
    <span class="n">dummy</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="n">scoring_metric</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span> <span class="ow">in</span> <span class="n">classifiers</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="n">results</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">mean_std_cross_val_scores</span><span class="p">(</span>
        <span class="n">model</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="n">scoring_metric</span>
    <span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Dummy</th>
      <th>Decision tree</th>
      <th>Random forests</th>
      <th>logistic regression</th>
      <th>decision tree</th>
      <th>random forest</th>
      <th>XGBoost</th>
      <th>LightGBM</th>
      <th>CatBoost</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>fit_time</th>
      <td>0.007 (+/- 0.000)</td>
      <td>0.463 (+/- 0.011)</td>
      <td>6.891 (+/- 0.075)</td>
      <td>0.736 (+/- 0.036)</td>
      <td>0.455 (+/- 0.009)</td>
      <td>6.854 (+/- 0.054)</td>
      <td>0.476 (+/- 0.024)</td>
      <td>0.233 (+/- 0.037)</td>
      <td>10.882 (+/- 0.230)</td>
    </tr>
    <tr>
      <th>score_time</th>
      <td>0.005 (+/- 0.000)</td>
      <td>0.020 (+/- 0.000)</td>
      <td>0.096 (+/- 0.002)</td>
      <td>0.018 (+/- 0.000)</td>
      <td>0.019 (+/- 0.000)</td>
      <td>0.094 (+/- 0.001)</td>
      <td>0.042 (+/- 0.003)</td>
      <td>0.027 (+/- 0.001)</td>
      <td>0.024 (+/- 0.001)</td>
    </tr>
    <tr>
      <th>test_score</th>
      <td>0.629 (+/- 0.007)</td>
      <td>0.813 (+/- 0.003)</td>
      <td>0.857 (+/- 0.004)</td>
      <td>0.850 (+/- 0.006)</td>
      <td>0.813 (+/- 0.003)</td>
      <td>0.857 (+/- 0.004)</td>
      <td>0.871 (+/- 0.004)</td>
      <td>0.871 (+/- 0.004)</td>
      <td>0.872 (+/- 0.003)</td>
    </tr>
    <tr>
      <th>train_score</th>
      <td>0.634 (+/- 0.004)</td>
      <td>1.000 (+/- 0.000)</td>
      <td>1.000 (+/- 0.000)</td>
      <td>0.851 (+/- 0.001)</td>
      <td>1.000 (+/- 0.000)</td>
      <td>1.000 (+/- 0.000)</td>
      <td>0.908 (+/- 0.001)</td>
      <td>0.892 (+/- 0.000)</td>
      <td>0.900 (+/- 0.001)</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p><strong>Some observations</strong></p>
<ul class="simple">
<li><p>Keep in mind all these results are with default hyperparameters</p></li>
<li><p>Ideally we would carry out hyperparameter optimization for all of them and then compare the results.</p></li>
<li><p>We are using a particular scoring metric (accuracy in this case)</p></li>
<li><p>We are scaling numeric features but it shouldn’t matter for these tree-based models.</p></li>
<li><p>Look at the std. Doesn’t look very high.</p>
<ul>
<li><p>The scores look more or less stable.</p></li>
</ul>
</li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Dummy</th>
      <th>Decision tree</th>
      <th>Random forests</th>
      <th>logistic regression</th>
      <th>decision tree</th>
      <th>random forest</th>
      <th>XGBoost</th>
      <th>LightGBM</th>
      <th>CatBoost</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>fit_time</th>
      <td>0.007 (+/- 0.000)</td>
      <td>0.463 (+/- 0.011)</td>
      <td>6.891 (+/- 0.075)</td>
      <td>0.736 (+/- 0.036)</td>
      <td>0.455 (+/- 0.009)</td>
      <td>6.854 (+/- 0.054)</td>
      <td>0.476 (+/- 0.024)</td>
      <td>0.233 (+/- 0.037)</td>
      <td>10.882 (+/- 0.230)</td>
    </tr>
    <tr>
      <th>score_time</th>
      <td>0.005 (+/- 0.000)</td>
      <td>0.020 (+/- 0.000)</td>
      <td>0.096 (+/- 0.002)</td>
      <td>0.018 (+/- 0.000)</td>
      <td>0.019 (+/- 0.000)</td>
      <td>0.094 (+/- 0.001)</td>
      <td>0.042 (+/- 0.003)</td>
      <td>0.027 (+/- 0.001)</td>
      <td>0.024 (+/- 0.001)</td>
    </tr>
    <tr>
      <th>test_score</th>
      <td>0.629 (+/- 0.007)</td>
      <td>0.813 (+/- 0.003)</td>
      <td>0.857 (+/- 0.004)</td>
      <td>0.850 (+/- 0.006)</td>
      <td>0.813 (+/- 0.003)</td>
      <td>0.857 (+/- 0.004)</td>
      <td>0.871 (+/- 0.004)</td>
      <td>0.871 (+/- 0.004)</td>
      <td>0.872 (+/- 0.003)</td>
    </tr>
    <tr>
      <th>train_score</th>
      <td>0.634 (+/- 0.004)</td>
      <td>1.000 (+/- 0.000)</td>
      <td>1.000 (+/- 0.000)</td>
      <td>0.851 (+/- 0.001)</td>
      <td>1.000 (+/- 0.000)</td>
      <td>1.000 (+/- 0.000)</td>
      <td>0.908 (+/- 0.001)</td>
      <td>0.892 (+/- 0.000)</td>
      <td>0.900 (+/- 0.001)</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<ul class="simple">
<li><p>Decision trees and random forests overfit</p>
<ul>
<li><p>Other models do not seem to overfit much.</p></li>
</ul>
</li>
<li><p>Fit times</p>
<ul>
<li><p>Decision trees are fast but not very accurate</p></li>
<li><p>LightGBM is faster than decision trees and more accurate!</p></li>
<li><p>CatBoost fit time is highest followed by random forests.</p></li>
<li><p>There is not much difference between the validation scores of XGBoost, LightGBM, and CatBoost but it is about 48x slower than LightGBM!</p></li>
<li><p>XGBoost and LightGBM are faster and more accurate than random forest!</p></li>
</ul>
</li>
<li><p>Scores times</p>
<ul>
<li><p>Prediction times are much smaller in all cases.</p></li>
</ul>
</li>
</ul>
</section>
<section id="what-classifier-should-i-use">
<h3>What classifier should I use?<a class="headerlink" href="#what-classifier-should-i-use" title="Permalink to this heading">#</a></h3>
<p><strong>Simple answer</strong></p>
<ul class="simple">
<li><p>Whichever gets the highest CV score making sure that you’re not overusing the validation set.</p></li>
</ul>
<p><strong>Interpretability</strong></p>
<ul class="simple">
<li><p>This is an area of growing interest and concern in ML.</p></li>
<li><p>How important is interpretability for you?</p></li>
<li><p>In the next class we’ll talk about interpretability of non-linear models.</p></li>
</ul>
<p><strong>Speed/code maintenance</strong></p>
<ul class="simple">
<li><p>Other considerations could be speed (fit and/or predict), maintainability of the code.</p></li>
</ul>
<p>Finally, you could use all of them! (Next videos.)</p>
</section>
</section>
<section id="averaging">
<h2>4. Averaging<a class="headerlink" href="#averaging" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>Video 4</p></li>
</ul>
<p>Earlier we looked at a bunch of classifiers:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">classifiers</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>dict_keys([&#39;logistic regression&#39;, &#39;decision tree&#39;, &#39;random forest&#39;, &#39;XGBoost&#39;, &#39;LightGBM&#39;, &#39;CatBoost&#39;])
</pre></div>
</div>
</div>
</div>
<p>What if we use all these models and let them vote during prediction time?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">VotingClassifier</span>

<span class="n">averaging_model</span> <span class="o">=</span> <span class="n">VotingClassifier</span><span class="p">(</span>
    <span class="nb">list</span><span class="p">(</span><span class="n">classifiers</span><span class="o">.</span><span class="n">items</span><span class="p">()),</span> <span class="n">voting</span><span class="o">=</span><span class="s2">&quot;soft&quot;</span>
<span class="p">)</span>  <span class="c1"># need the list() here for cross_val to work!</span>
</pre></div>
</div>
</div>
</div>
<p>This <code class="docutils literal notranslate"><span class="pre">VotingClassifier</span></code> will take a <em>vote</em> using the predictions of the constituent classifier pipelines.</p>
<p>Main parameter: <code class="docutils literal notranslate"><span class="pre">voting</span></code></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">voting='hard'</span></code></p>
<ul>
<li><p>it uses the output of <code class="docutils literal notranslate"><span class="pre">predict</span></code> and actually votes.</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">voting='soft'</span></code></p>
<ul>
<li><p>with <code class="docutils literal notranslate"><span class="pre">voting='soft'</span></code> it averages the output of <code class="docutils literal notranslate"><span class="pre">predict_proba</span></code> and then thresholds / takes the larger.</p></li>
</ul>
</li>
<li><p>The choice depends on whether you trust <code class="docutils literal notranslate"><span class="pre">predict_proba</span></code> from your base classifiers - if so, it’s nice to access that information.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">averaging_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>What happens when you <code class="docutils literal notranslate"><span class="pre">fit</span></code> a <code class="docutils literal notranslate"><span class="pre">VotingClassifier</span></code>?</p>
<ul>
<li><p>It will fit all constituent models.</p></li>
</ul>
</li>
</ul>
<p>Note: it seems sklearn requires us to actually call <code class="docutils literal notranslate"><span class="pre">fit</span></code> on the <code class="docutils literal notranslate"><span class="pre">VotingClassifier</span></code>, instead of passing in pre-fit models. This is an implementation choice rather than a conceptual limitation.</p>
<p>Let’s look at particular test examples where <code class="docutils literal notranslate"><span class="pre">income</span></code> is “&gt;50k” (y=1):</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">test_g50k</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">test_df</span><span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="s2">&quot;income == &#39;&gt;50K&#39;&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;income&quot;</span><span class="p">])</span>
<span class="p">)</span>
<span class="n">test_l50k</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">test_df</span><span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="s2">&quot;income == &#39;&lt;=50K&#39;&quot;</span><span class="p">)</span>
    <span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;income&quot;</span><span class="p">])</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;Voting classifier&quot;</span><span class="p">:</span> <span class="n">averaging_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_g50k</span><span class="p">)}</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Voting classifier</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>&gt;50K</td>
    </tr>
    <tr>
      <th>1</th>
      <td>&gt;50K</td>
    </tr>
    <tr>
      <th>2</th>
      <td>&gt;50K</td>
    </tr>
    <tr>
      <th>3</th>
      <td>&lt;=50K</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>For hard voting, these are the votes:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">r1</span> <span class="o">=</span> <span class="p">{</span>
    <span class="n">name</span><span class="p">:</span> <span class="n">classifier</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_g50k</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">classifier</span> <span class="ow">in</span> <span class="n">averaging_model</span><span class="o">.</span><span class="n">named_estimators_</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
<span class="p">}</span>
<span class="n">data</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">r1</span><span class="p">)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Voting classifier</th>
      <th>logistic regression</th>
      <th>decision tree</th>
      <th>random forest</th>
      <th>XGBoost</th>
      <th>LightGBM</th>
      <th>CatBoost</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>&gt;50K</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>&gt;50K</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>&gt;50K</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>&lt;=50K</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>For soft voting, these are the scores:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">r1</span> <span class="o">=</span> <span class="p">{</span>
    <span class="n">name</span><span class="p">:</span> <span class="n">classifier</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">test_g50k</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">classifier</span> <span class="ow">in</span> <span class="n">averaging_model</span><span class="o">.</span><span class="n">named_estimators_</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
<span class="p">}</span>
<span class="n">r1</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;logistic regression&#39;: array([[2.30926389e-14, 1.00000000e+00],
        [4.18799985e-01, 5.81200015e-01],
        [4.96459494e-01, 5.03540506e-01],
        [8.87596360e-01, 1.12403640e-01]]),
 &#39;decision tree&#39;: array([[0., 1.],
        [0., 1.],
        [1., 0.],
        [1., 0.]]),
 &#39;random forest&#39;: array([[0.  , 1.  ],
        [0.31, 0.69],
        [0.37, 0.63],
        [0.57, 0.43]]),
 &#39;XGBoost&#39;: array([[3.9428473e-04, 9.9960572e-01],
        [2.5976986e-01, 7.4023014e-01],
        [3.1037945e-01, 6.8962055e-01],
        [8.1797528e-01, 1.8202470e-01]], dtype=float32),
 &#39;LightGBM&#39;: array([[0.00187645, 0.99812355],
        [0.28722892, 0.71277108],
        [0.28457261, 0.71542739],
        [0.8095596 , 0.1904404 ]]),
 &#39;CatBoost&#39;: array([[0.00151693, 0.99848307],
        [0.28344311, 0.71655689],
        [0.32029146, 0.67970854],
        [0.81534647, 0.18465353]])}
</pre></div>
</div>
</div>
</div>
<p>(Aside: the probability scores from <code class="docutils literal notranslate"><span class="pre">DecisionTreeClassifier</span></code> are pretty bad)</p>
<p>Let’s see how well this model performs.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">results</span><span class="p">[</span><span class="s2">&quot;Voting&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">mean_std_cross_val_scores</span><span class="p">(</span><span class="n">averaging_model</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Dummy</th>
      <th>Decision tree</th>
      <th>Random forests</th>
      <th>logistic regression</th>
      <th>decision tree</th>
      <th>random forest</th>
      <th>XGBoost</th>
      <th>LightGBM</th>
      <th>CatBoost</th>
      <th>Voting</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>fit_time</th>
      <td>0.007 (+/- 0.000)</td>
      <td>0.463 (+/- 0.011)</td>
      <td>6.891 (+/- 0.075)</td>
      <td>0.736 (+/- 0.036)</td>
      <td>0.455 (+/- 0.009)</td>
      <td>6.854 (+/- 0.054)</td>
      <td>0.476 (+/- 0.024)</td>
      <td>0.233 (+/- 0.037)</td>
      <td>10.882 (+/- 0.230)</td>
      <td>19.365 (+/- 0.258)</td>
    </tr>
    <tr>
      <th>score_time</th>
      <td>0.005 (+/- 0.000)</td>
      <td>0.020 (+/- 0.000)</td>
      <td>0.096 (+/- 0.002)</td>
      <td>0.018 (+/- 0.000)</td>
      <td>0.019 (+/- 0.000)</td>
      <td>0.094 (+/- 0.001)</td>
      <td>0.042 (+/- 0.003)</td>
      <td>0.027 (+/- 0.001)</td>
      <td>0.024 (+/- 0.001)</td>
      <td>0.190 (+/- 0.005)</td>
    </tr>
    <tr>
      <th>test_score</th>
      <td>0.629 (+/- 0.007)</td>
      <td>0.813 (+/- 0.003)</td>
      <td>0.857 (+/- 0.004)</td>
      <td>0.850 (+/- 0.006)</td>
      <td>0.813 (+/- 0.003)</td>
      <td>0.857 (+/- 0.004)</td>
      <td>0.871 (+/- 0.004)</td>
      <td>0.871 (+/- 0.004)</td>
      <td>0.872 (+/- 0.003)</td>
      <td>0.868 (+/- 0.003)</td>
    </tr>
    <tr>
      <th>train_score</th>
      <td>0.634 (+/- 0.004)</td>
      <td>1.000 (+/- 0.000)</td>
      <td>1.000 (+/- 0.000)</td>
      <td>0.851 (+/- 0.001)</td>
      <td>1.000 (+/- 0.000)</td>
      <td>1.000 (+/- 0.000)</td>
      <td>0.908 (+/- 0.001)</td>
      <td>0.892 (+/- 0.000)</td>
      <td>0.900 (+/- 0.001)</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>It appears that here we didn’t do much better than our best classifier!</p>
<p>Let’s try removing decision tree classifier.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">classifiers_ndt</span> <span class="o">=</span> <span class="n">classifiers</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="k">del</span> <span class="n">classifiers_ndt</span><span class="p">[</span><span class="s2">&quot;decision tree&quot;</span><span class="p">]</span>
<span class="n">averaging_model_ndt</span> <span class="o">=</span> <span class="n">VotingClassifier</span><span class="p">(</span>
    <span class="nb">list</span><span class="p">(</span><span class="n">classifiers_ndt</span><span class="o">.</span><span class="n">items</span><span class="p">()),</span> <span class="n">voting</span><span class="o">=</span><span class="s2">&quot;soft&quot;</span>
<span class="p">)</span>  <span class="c1"># need the list() here for cross_val to work!</span>

<span class="n">results</span><span class="p">[</span><span class="s2">&quot;Voting_ndt&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">mean_std_cross_val_scores</span><span class="p">(</span>
    <span class="n">averaging_model_ndt</span><span class="p">,</span>
    <span class="n">X_train</span><span class="p">,</span>
    <span class="n">y_train</span><span class="p">,</span>
    <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">scoring</span><span class="o">=</span><span class="n">scoring_metric</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Dummy</th>
      <th>Decision tree</th>
      <th>Random forests</th>
      <th>logistic regression</th>
      <th>decision tree</th>
      <th>random forest</th>
      <th>XGBoost</th>
      <th>LightGBM</th>
      <th>CatBoost</th>
      <th>Voting</th>
      <th>Voting_ndt</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>fit_time</th>
      <td>0.007 (+/- 0.000)</td>
      <td>0.463 (+/- 0.011)</td>
      <td>6.891 (+/- 0.075)</td>
      <td>0.736 (+/- 0.036)</td>
      <td>0.455 (+/- 0.009)</td>
      <td>6.854 (+/- 0.054)</td>
      <td>0.476 (+/- 0.024)</td>
      <td>0.233 (+/- 0.037)</td>
      <td>10.882 (+/- 0.230)</td>
      <td>19.365 (+/- 0.258)</td>
      <td>18.691 (+/- 0.400)</td>
    </tr>
    <tr>
      <th>score_time</th>
      <td>0.005 (+/- 0.000)</td>
      <td>0.020 (+/- 0.000)</td>
      <td>0.096 (+/- 0.002)</td>
      <td>0.018 (+/- 0.000)</td>
      <td>0.019 (+/- 0.000)</td>
      <td>0.094 (+/- 0.001)</td>
      <td>0.042 (+/- 0.003)</td>
      <td>0.027 (+/- 0.001)</td>
      <td>0.024 (+/- 0.001)</td>
      <td>0.190 (+/- 0.005)</td>
      <td>0.171 (+/- 0.003)</td>
    </tr>
    <tr>
      <th>test_score</th>
      <td>0.629 (+/- 0.007)</td>
      <td>0.813 (+/- 0.003)</td>
      <td>0.857 (+/- 0.004)</td>
      <td>0.850 (+/- 0.006)</td>
      <td>0.813 (+/- 0.003)</td>
      <td>0.857 (+/- 0.004)</td>
      <td>0.871 (+/- 0.004)</td>
      <td>0.871 (+/- 0.004)</td>
      <td>0.872 (+/- 0.003)</td>
      <td>0.868 (+/- 0.003)</td>
      <td>0.871 (+/- 0.004)</td>
    </tr>
    <tr>
      <th>train_score</th>
      <td>0.634 (+/- 0.004)</td>
      <td>1.000 (+/- 0.000)</td>
      <td>1.000 (+/- 0.000)</td>
      <td>0.851 (+/- 0.001)</td>
      <td>1.000 (+/- 0.000)</td>
      <td>1.000 (+/- 0.000)</td>
      <td>0.908 (+/- 0.001)</td>
      <td>0.892 (+/- 0.000)</td>
      <td>0.900 (+/- 0.001)</td>
      <td>NaN</td>
      <td>0.921 (+/- 0.001)</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Still the results are not better than the best performing model.</p>
<ul class="simple">
<li><p>It didn’t happen here but how could the average do better than the best model???</p>
<ul>
<li><p>From the perspective of the best estimator (in this case CatBoost), why are you adding on worse estimators??</p></li>
</ul>
</li>
</ul>
<p>Here’s how this can work:</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Example</p></th>
<th class="head"><p>log reg</p></th>
<th class="head"><p>rand forest</p></th>
<th class="head"><p>cat boost</p></th>
<th class="head"><p>Averaged model</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>1</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>❌</p></td>
<td><p>✅✅❌=&gt;✅</p></td>
</tr>
<tr class="row-odd"><td><p>2</p></td>
<td><p>✅</p></td>
<td><p>❌</p></td>
<td><p>✅</p></td>
<td><p>✅❌✅=&gt;✅</p></td>
</tr>
<tr class="row-even"><td><p>3</p></td>
<td><p>❌</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>❌✅✅=&gt;✅</p></td>
</tr>
</tbody>
</table>
<p>In short, as long as the different models make different mistakes, this can work.</p>
<p>Why not always do this?</p>
<ol class="arabic simple">
<li><p><code class="docutils literal notranslate"><span class="pre">fit</span></code>/<code class="docutils literal notranslate"><span class="pre">predict</span></code> time.</p></li>
<li><p>Reduction in interpretability.</p></li>
<li><p>Reduction in code maintainability (e.g. Netflix prize).</p></li>
</ol>
<section id="what-kind-of-estimators-can-we-combine">
<h3>What kind of estimators can we combine?<a class="headerlink" href="#what-kind-of-estimators-can-we-combine" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>You can combine</p>
<ul>
<li><p>completely different estimators, or similar estimators.</p></li>
<li><p>estimators trained on different samples.</p></li>
<li><p>estimators with different hyperparameter values.</p></li>
</ul>
</li>
</ul>
</section>
</section>
<section id="stacking">
<h2>5. Stacking<a class="headerlink" href="#stacking" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>Video 5</p></li>
</ul>
<ul class="simple">
<li><p>Another type of ensemble is stacking.</p></li>
<li><p>Instead of averaging the outputs of each estimator, instead use their outputs as <em>inputs to another model</em>.</p></li>
<li><p>By default for classification, it uses logistic regression.</p>
<ul>
<li><p>We don’t need a complex model here necessarily, more of a weighted average.</p></li>
<li><p>The features going into the logistic regression are the classifier outputs, <em>not</em> the original features!</p></li>
<li><p>So the number of coefficients = the number of base estimators!</p></li>
</ul>
</li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">StackingClassifier</span>
</pre></div>
</div>
</div>
</div>
<p>The code starts to get too slow here; so we’ll remove CatBoost.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">classifiers_nocat</span> <span class="o">=</span> <span class="n">classifiers</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="k">del</span> <span class="n">classifiers_nocat</span><span class="p">[</span><span class="s2">&quot;CatBoost&quot;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">stacking_model</span> <span class="o">=</span> <span class="n">StackingClassifier</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">classifiers_nocat</span><span class="o">.</span><span class="n">items</span><span class="p">()))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">stacking_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<p>What’s going on in here?</p>
<ul class="simple">
<li><p>It is doing cross-validation by itself by default (see <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingClassifier.html">documentation</a>)</p>
<ul>
<li><p>It is fitting the base estimators on the training fold</p></li>
<li><p>And the predicting on the validation fold</p></li>
<li><p>And then fitting the meta-estimator on that output (on the validation fold)</p></li>
</ul>
</li>
</ul>
<blockquote>
<div><p>Note that estimators_ are fitted on the full X (not sure why it needs to do this) while final_estimator_ is trained using cross-validated predictions of the base estimators using cross_val_predict.</p>
</div></blockquote>
<p>Here is the input features (X) to the meta-model:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">valid_sample</span> <span class="o">=</span> <span class="n">train_df</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;income&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">r3</span> <span class="o">=</span> <span class="p">{</span>
    <span class="n">name</span><span class="p">:</span> <span class="n">pipe</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">valid_sample</span><span class="p">)</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">pipe</span><span class="p">)</span> <span class="ow">in</span> <span class="n">stacking_model</span><span class="o">.</span><span class="n">named_estimators_</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
<span class="p">}</span>
<span class="n">r3</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;logistic regression&#39;: array([[4.33363244e-01, 5.66636756e-01],
        [9.99015113e-01, 9.84886989e-04],
        [8.60862691e-01, 1.39137309e-01],
        [9.95295942e-01, 4.70405800e-03]]),
 &#39;decision tree&#39;: array([[1., 0.],
        [1., 0.],
        [1., 0.],
        [1., 0.]]),
 &#39;random forest&#39;: array([[0.88, 0.12],
        [1.  , 0.  ],
        [0.95, 0.05],
        [1.  , 0.  ]]),
 &#39;XGBoost&#39;: array([[0.7709182 , 0.2290818 ],
        [0.9985829 , 0.00141712],
        [0.92655057, 0.07344944],
        [0.99416995, 0.00583006]], dtype=float32),
 &#39;LightGBM&#39;: array([[0.56629894, 0.43370106],
        [0.99263965, 0.00736035],
        [0.91995188, 0.08004812],
        [0.99629847, 0.00370153]])}
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Our meta-model is logistic regression (which it is by default).</p></li>
<li><p>Let’s look at the learned coefficients.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
    <span class="n">data</span><span class="o">=</span><span class="n">stacking_model</span><span class="o">.</span><span class="n">final_estimator_</span><span class="o">.</span><span class="n">coef_</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
    <span class="n">index</span><span class="o">=</span><span class="n">classifiers_nocat</span><span class="o">.</span><span class="n">keys</span><span class="p">(),</span>
    <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Coefficient&quot;</span><span class="p">],</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Coefficient</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>logistic regression</th>
      <td>0.782704</td>
    </tr>
    <tr>
      <th>decision tree</th>
      <td>-0.011131</td>
    </tr>
    <tr>
      <th>random forest</th>
      <td>0.216597</td>
    </tr>
    <tr>
      <th>XGBoost</th>
      <td>2.088613</td>
    </tr>
    <tr>
      <th>LightGBM</th>
      <td>3.602162</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<ul class="simple">
<li><p>It seems that the LightGBM is being trusted the most.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">stacking_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_g50k</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([&#39;&gt;50K&#39;, &#39;&gt;50K&#39;, &#39;&gt;50K&#39;, &#39;&lt;=50K&#39;], dtype=object)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">stacking_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">test_g50k</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[0.03381923, 0.96618077],
       [0.19976582, 0.80023418],
       [0.22636102, 0.77363898],
       [0.88812688, 0.11187312]])
</pre></div>
</div>
</div>
</div>
<p>(This is the <code class="docutils literal notranslate"><span class="pre">predict_proba</span></code> from logistic regression)</p>
<p>Let’s see how well this model performs.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">results</span><span class="p">[</span><span class="s2">&quot;Stacking_nocat&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">mean_std_cross_val_scores</span><span class="p">(</span>
    <span class="n">stacking_model</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="n">scoring_metric</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Dummy</th>
      <th>Decision tree</th>
      <th>Random forests</th>
      <th>logistic regression</th>
      <th>decision tree</th>
      <th>random forest</th>
      <th>XGBoost</th>
      <th>LightGBM</th>
      <th>CatBoost</th>
      <th>Voting</th>
      <th>Voting_ndt</th>
      <th>Stacking_nocat</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>fit_time</th>
      <td>0.007 (+/- 0.000)</td>
      <td>0.463 (+/- 0.011)</td>
      <td>6.891 (+/- 0.075)</td>
      <td>0.736 (+/- 0.036)</td>
      <td>0.455 (+/- 0.009)</td>
      <td>6.854 (+/- 0.054)</td>
      <td>0.476 (+/- 0.024)</td>
      <td>0.233 (+/- 0.037)</td>
      <td>10.882 (+/- 0.230)</td>
      <td>19.365 (+/- 0.258)</td>
      <td>18.691 (+/- 0.400)</td>
      <td>42.141 (+/- 0.354)</td>
    </tr>
    <tr>
      <th>score_time</th>
      <td>0.005 (+/- 0.000)</td>
      <td>0.020 (+/- 0.000)</td>
      <td>0.096 (+/- 0.002)</td>
      <td>0.018 (+/- 0.000)</td>
      <td>0.019 (+/- 0.000)</td>
      <td>0.094 (+/- 0.001)</td>
      <td>0.042 (+/- 0.003)</td>
      <td>0.027 (+/- 0.001)</td>
      <td>0.024 (+/- 0.001)</td>
      <td>0.190 (+/- 0.005)</td>
      <td>0.171 (+/- 0.003)</td>
      <td>0.202 (+/- 0.004)</td>
    </tr>
    <tr>
      <th>test_score</th>
      <td>0.629 (+/- 0.007)</td>
      <td>0.813 (+/- 0.003)</td>
      <td>0.857 (+/- 0.004)</td>
      <td>0.850 (+/- 0.006)</td>
      <td>0.813 (+/- 0.003)</td>
      <td>0.857 (+/- 0.004)</td>
      <td>0.871 (+/- 0.004)</td>
      <td>0.871 (+/- 0.004)</td>
      <td>0.872 (+/- 0.003)</td>
      <td>0.868 (+/- 0.003)</td>
      <td>0.871 (+/- 0.004)</td>
      <td>0.872 (+/- 0.003)</td>
    </tr>
    <tr>
      <th>train_score</th>
      <td>0.634 (+/- 0.004)</td>
      <td>1.000 (+/- 0.000)</td>
      <td>1.000 (+/- 0.000)</td>
      <td>0.851 (+/- 0.001)</td>
      <td>1.000 (+/- 0.000)</td>
      <td>1.000 (+/- 0.000)</td>
      <td>0.908 (+/- 0.001)</td>
      <td>0.892 (+/- 0.000)</td>
      <td>0.900 (+/- 0.001)</td>
      <td>NaN</td>
      <td>0.921 (+/- 0.001)</td>
      <td>0.900 (+/- 0.006)</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<ul class="simple">
<li><p>The situation here is a bit mind-boggling.</p></li>
<li><p>On each fold of cross-validation it is doing cross-validation.</p></li>
<li><p>This is really loops within loops within loops within loops…</p></li>
</ul>
<ul class="simple">
<li><p>We can also try a different final estimator:</p></li>
<li><p>Let’s <code class="docutils literal notranslate"><span class="pre">DecisionTreeClassifier</span></code> as a final estimator.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">stacking_model_tree</span> <span class="o">=</span> <span class="n">StackingClassifier</span><span class="p">(</span>
    <span class="nb">list</span><span class="p">(</span><span class="n">classifiers_nocat</span><span class="o">.</span><span class="n">items</span><span class="p">()),</span> <span class="n">final_estimator</span><span class="o">=</span><span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The results are not very good. But we can look at the tree:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">stacking_model_tree</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">display_tree</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">classifiers_nocat</span><span class="o">.</span><span class="n">keys</span><span class="p">()),</span> <span class="n">stacking_model_tree</span><span class="o">.</span><span class="n">final_estimator_</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/9d556d2828ceda5ca0dbcf33a0640436b8b8de668b59a9784ec9a6cb5fea7183.svg" src="../_images/9d556d2828ceda5ca0dbcf33a0640436b8b8de668b59a9784ec9a6cb5fea7183.svg" /></div>
</div>
<ul class="simple">
<li><p>What is an advantage of ensembling multiple models as opposed to just choosing one of them?</p>
<ul>
<li><p>You may get a better score.</p></li>
</ul>
</li>
<li><p>What is an disadvantage of ensembling multiple models as opposed to just choosing one of them?</p>
<ul>
<li><p>Slower, more code maintenance issues.</p></li>
</ul>
</li>
</ul>
<section id="an-effective-strategy">
<h3>An effective strategy<a class="headerlink" href="#an-effective-strategy" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>Randomly generate a bunch of models with different hyperparameter configurations, and then stack all the models.</p></li>
</ul>
</section>
</section>
<section id="summary">
<h2>Summary<a class="headerlink" href="#summary" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>You have a number of models in your toolbox now.</p></li>
<li><p>Ensembles are usually pretty effective.</p>
<ul>
<li><p>Tree-based classifiers are particularly popular and effective on a wide range of problems.</p></li>
<li><p>But they trade off code complexity and speed for prediction accuracy.</p></li>
<li><p>Don’t forget that hyperparameter optimization multiplies the slowness of the code!</p></li>
</ul>
</li>
<li><p>Stacking is a bit slower than voting, but generally higher accuracy.</p>
<ul>
<li><p>As a bonus, you get to see the coefficients for each base classifier.</p></li>
</ul>
</li>
<li><p>All the above models have equivalent regression models.</p></li>
</ul>
<section id="relevant-papers">
<h3>Relevant papers<a class="headerlink" href="#relevant-papers" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p><a class="reference external" href="http://jmlr.org/papers/volume15/delgado14a/delgado14a.pdf">Fernandez-Delgado et al. 2014</a> compared 179 classifiers on 121 datasets:</p>
<ul>
<li><p>First best class of methods was Random Forest and second best class of methods was (RBF) SVMs.</p></li>
</ul>
</li>
<li><p>If you like to read original papers <a class="reference external" href="https://www.stat.berkeley.edu/~breiman/randomforest2001.pdf">here</a> is the original paper on Random Forests by Leo Breiman.</p></li>
</ul>
</section>
<section id="annotated-true-or-false-questions-on-random-forests-class-discussion">
<h3>(Annotated) True or False questions on Random Forests (Class discussion)<a class="headerlink" href="#annotated-true-or-false-questions-on-random-forests-class-discussion" title="Permalink to this heading">#</a></h3>
<ol class="arabic simple">
<li><p>Every tree in a random forest uses a different bootstrap sample of the training set. (True)</p></li>
<li><p>To train a tree in a random forest, we first randomly select a subset of features. The tree is then restricted to only using those features. (False)</p></li>
<li><p>A reasonable implementation of <code class="docutils literal notranslate"><span class="pre">predict_proba</span></code> for random forests would be for each tree to “vote” and then normalize these vote counts into probabilities. (True)</p></li>
<li><p>Increasing the hyperparameter max_features (the number of features to consider for a split) makes the model more complex and moves the fundamental tradeoff toward lower training error. (True)</p></li>
<li><p>A random forest with only one tree is likely to get a higher training error than a decision tree of the same depth. (True)</p></li>
</ol>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "conda-env-571-py"
        },
        kernelOptions: {
            name: "conda-env-571-py",
            path: "./_lectures"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'conda-env-571-py'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#lecture-5-ensembles">Lecture 5: Ensembles</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#lecture-learning-objectives">Lecture learning objectives</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#motivation">1. Motivation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-netflix-prize">The Netflix prize</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#popularity-of-treed-based-models">Popularity of treed-based models</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#data">Data</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#do-we-have-class-imbalance">Do we have class imbalance?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#baselines">Baselines</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#dummyclassifier-baseline"><code class="docutils literal notranslate"><span class="pre">DummyClassifier</span></code> baseline</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#decisiontreeclassifier-baseline"><code class="docutils literal notranslate"><span class="pre">DecisionTreeClassifier</span></code> baseline</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#random-forests">2. Random forests</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#randomforestclassifier"><code class="docutils literal notranslate"><span class="pre">RandomForestClassifier</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-a-random-forest">What is a random forest?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Random forests</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-random-forests-classifier">The random forests classifier</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#example">Example</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#some-important-hyperparameters">Some important hyperparameters:</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#random-forests-number-of-trees-n-estimators-and-the-fundamental-tradeoff">Random forests: number of trees (<code class="docutils literal notranslate"><span class="pre">n_estimators</span></code>) and the fundamental tradeoff</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#number-of-trees-and-fundamental-trade-off">Number of trees and fundamental trade-off</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#why-does-this-work">Why does this work?</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#random-forests-vs-decision-trees">Random forests vs decision trees</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#other-fancier-popular-tree-based-models">3. Other fancier popular tree-based models</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#xgboost">XGBoost</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#lightgbm">LightGBM</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#catboost">CatBoost</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#what-classifier-should-i-use">What classifier should I use?</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#averaging">4. Averaging</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#what-kind-of-estimators-can-we-combine">What kind of estimators can we combine?</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#stacking">5. Stacking</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#an-effective-strategy">An effective strategy</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#summary">Summary</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#relevant-papers">Relevant papers</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#annotated-true-or-false-questions-on-random-forests-class-discussion">(Annotated) True or False questions on Random Forests (Class discussion)</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Varada Kolhatkar and Joel Östblom
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>